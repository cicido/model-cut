{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AdaIN\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "importlib.reload(AdaIN)\n",
    "import construct_input_data\n",
    "import os\n",
    "import get_x_w_y\n",
    "from lib.decompose import dictionary\n",
    "import torch_net_param\n",
    "importlib.reload(get_x_w_y)\n",
    "\n",
    "print('*'*20 + \"load image load\" + '*' * 20)\n",
    "dataDir = '/data/mydata/val/ilsvrc2012_val'\n",
    "dataPickle = \"input/data.pickle\"\n",
    "if os.path.isfile(dataPickle):\n",
    "    print('%s exists' %dataPickle)\n",
    "else:\n",
    "    construct_input_data.freeze_image_data(dataDir,dataPickle)\n",
    "input_data = construct_input_data.load_image_data(dataPickle)\n",
    "print('load end!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进一步计算decoder的输入，即AdaIN的输出.\n",
    "def get_AdaIN_input(input_data, alpha, vgg_t7_file):\n",
    "    input_shape = input_data.shape\n",
    "    nPicsPerBatch = input_shape[1]\n",
    "    nBatches = input_shape[0]\n",
    "    nPics = nPicsPerBatch * nBatches\n",
    "    with tf.Graph().as_default() as g, tf.Session(graph=g) as sess, tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:\n",
    "        c_holder = tf.placeholder(tf.float32,[1,None,None,None],name=\"input_content\")\n",
    "        s_holder = tf.placeholder(tf.float32,[1,None,None,None],name=\"input_style\")\n",
    "        print(c_holder)\n",
    "        print(s_holder)\n",
    "        \n",
    "        c_vgg,_ = torch_net_param.construct_net(c_holder, g, vgg_t7_file)\n",
    "        s_vgg,_ = torch_net_param.construct_net(s_holder, g, vgg_t7_file)\n",
    " \n",
    "        stylized_content = AdaIN.AdaIN(c_vgg, s_vgg, alpha)\n",
    "        print(\"sc_shape:\",stylized_content.shape)\n",
    "        is_first = True\n",
    "        output_data = None\n",
    "        \n",
    "        for i in range(nPics):\n",
    "            print(\"i:\",i)\n",
    "            batch_idx = np.random.randint(nBatches,size=(2,))\n",
    "            pics_idx = np.random.randint(nPicsPerBatch,size=(2,))\n",
    "            c = np.expand_dims(input_data[batch_idx[0]][pics_idx[0]],axis=0)\n",
    "            s = np.expand_dims(input_data[batch_idx[1]][pics_idx[1]],axis=0)\n",
    "            #print(\"c.shape:\",c.shape)\n",
    "            #print(\"s.shape:\",s.shape)\n",
    "            res = sess.run(stylized_content,feed_dict={c_holder:c,s_holder:s})\n",
    "            print(\"res.shape:\",res.shape)       \n",
    "            a,b = divmod(i,nPicsPerBatch)\n",
    "            if is_first:\n",
    "                output_shape = [nBatches,nPicsPerBatch] + list(res.shape[1:])\n",
    "                output_data = np.ndarray(shape=output_shape)\n",
    "                is_first = False\n",
    "            output_data[a][b] = np.squeeze(res, axis=0)\n",
    "        return output_data\n",
    "\n",
    "print('*'*20 + \"decoder_input_data\" + '*'*20)\n",
    "decoder_dataPickle = \"input/decoder_image_val_data.pickle\"\n",
    "decoder_input_data = None\n",
    "if os.path.isfile(decoder_dataPickle):\n",
    "    print('%s exists' %decoder_dataPickle)\n",
    "    decoder_input_data = construct_input_data.load_image_data(decoder_dataPickle)\n",
    "else:\n",
    "    vgg_t7 = 'models/param-0.pickle'\n",
    "    alpha = 1\n",
    "    decoder_input_data = get_AdaIN_input(input_data, alpha, vgg_t7)\n",
    "    construct_input_data.freeze_data(decoder_input_data,decoder_dataPickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_net_param\n",
    "importlib.reload(torch_net_param)\n",
    "print('*'*20 + '抽取decoder.t7' + '*'*20)\n",
    "#抽取t7模型参数，抽取后的结果保存到文件gt_param_file,以构建网络\n",
    "decoder_file = 'models/decoder.t7'\n",
    "gt_param_file = 'models/decoder-param-0.pickle'\n",
    "if os.path.isfile(gt_param_file):\n",
    "    print('%s exists' %gt_param_file)\n",
    "else:\n",
    "    torch_net_param.extract_net_param_from_t7(decoder_file,gt_param_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g, tf.Session(graph=g) as sess, tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:\n",
    "    ph = tf.placeholder(dtype=tf.float32,shape=(1,64,64,512))\n",
    "    c = torch_net_param.construct_net(ph,g,gt_param_file)\n",
    "    for i in g.get_operations():\n",
    "        Y_tensor = g.get_tensor_by_name(i.name + \":0\")\n",
    "        print(Y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_net(input_net_param_file,input_data,top_name,bottom_name):\n",
    "    feats_Y, points_dict,W,conv_map = get_x_w_y.get_gtY(gt_param_file,input_data,top_name)\n",
    "    feats_X = get_x_w_y.get_X(input_net_param_file,input_data,top_name,points_dict)\n",
    "    print(conv_map)\n",
    "\n",
    "    feats_W = W.transpose((3,2,0,1)) #(n,c,h,w)\n",
    "    feats_X = feats_X.transpose((0,3,1,2)) #(N,c,h,w)\n",
    "    output = dictionary(feats_X,feats_W,feats_Y,rank = int(feats_W.shape[1]/2))\n",
    "    idx = output[0]\n",
    "    newW = output[1].transpose(2,3,1,0)\n",
    "    newB = output[2]\n",
    "    net_param = torch_net_param.load_net_param(input_net_param_file)\n",
    "    top_idx = conv_map[top_name]\n",
    "    bottom_idx = conv_map[bottom_name]\n",
    "    print(\"top_idx,bootom_idx:\",top_idx,bottom_idx)\n",
    "\n",
    "    print(\"bottom size:\")\n",
    "    bottom_val = net_param[bottom_idx]['conv']\n",
    "    print(bottom_val[0].shape)\n",
    "    bottom_val[0] = bottom_val[0][...,idx]\n",
    "    print(bottom_val[0].shape)\n",
    "    bottom_val[2] = bottom_val[2][idx]\n",
    "    print(bottom_val[2].shape)\n",
    "\n",
    "    print(\"top size:\") \n",
    "    top_val = net_param[top_idx]['conv']\n",
    "    print(top_val[0].shape)\n",
    "    print(top_val[2].shape)\n",
    "    top_val[0] = newW\n",
    "    top_val[2] = top_val[2] + newB\n",
    "    print(top_val[0].shape)\n",
    "    print(top_val[2].shape)\n",
    "\n",
    "    outfile = '.'.join([input_net_param_file,top_name,bottom_name])\n",
    "    torch_net_param.freeze_net_param(net_param,outfile)\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dict = {'Conv2D': 1, 'Conv2D_1': 5, 'Conv2D_2': 8, 'Conv2D_3': 11, 'Conv2D_4': 14, 'Conv2D_5': 18, 'Conv2D_6': 21, 'Conv2D_7': 25, 'Conv2D_8': 28}\n",
    "\n",
    "conv_layer = sorted(conv_dict.keys())#[1:]\n",
    "top_bottom_pair_list = zip(conv_layer[1:],conv_layer[:-1])\n",
    "outfile = 'models/decoder-param-0.pickle'\n",
    "for top_bottom in top_bottom_pair_list:\n",
    "    top_name,bottom_name = top_bottom\n",
    "    print(top_name,bottom_name)\n",
    "    outfile = modify_net(outfile,decoder_input_data,top_name,bottom_name)    \n",
    "print(outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
